{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1496686f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Projects\\\\BioX_and_WnCC-Brain_Tumor_Segmentation\\\\Brain_Tumor_Segmentation\\\\Week_3&4\\\\archive\\\\BraTS2021_Training_Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-275862103.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m patients = sorted([\n\u001b[1;32m     96\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BraTS2021_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m ])\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Projects\\\\BioX_and_WnCC-Brain_Tumor_Segmentation\\\\Brain_Tumor_Segmentation\\\\Week_3&4\\\\archive\\\\BraTS2021_Training_Data'"
     ]
    }
   ],
   "source": [
    "# ===================== CORE IMPORTS =====================\n",
    "import os\n",
    "import cv2\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "# =======================================================\n",
    "\n",
    "# ===================== GPU SAFETY =====================\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "# =====================================================\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "database_path = r\"D:\\Projects\\BioX_and_WnCC-Brain_Tumor_Segmentation\\Brain_Tumor_Segmentation\\Week_3&4\\archive\\BraTS2021_Training_Data\"\n",
    "\n",
    "IMG_SIZE = 128\n",
    "SLICES_PER_STEP = 16     # ðŸ”¥ CRITICAL (NOT 80)\n",
    "PATIENT_BATCH = 1        # ðŸ”¥ MUST BE 1\n",
    "EPOCHS = 20\n",
    "DTYPE = np.float32\n",
    "\n",
    "# ---------------- LOGGING ----------------\n",
    "def log(msg):\n",
    "    print(f\"[INFO] {msg}\")\n",
    "\n",
    "# ---------------- MEMORY-SAFE SLICE LOADER ----------------\n",
    "def load_random_slices(path):\n",
    "    img = nib.load(path)\n",
    "    data = img.dataobj\n",
    "\n",
    "    z = data.shape[2]\n",
    "    center = z // 2\n",
    "    half = SLICES_PER_STEP // 2\n",
    "    start = max(0, center - half)\n",
    "    end = min(z, center + half)\n",
    "\n",
    "    slices = []\n",
    "    for i in range(start, end):\n",
    "        sl = np.asarray(data[:, :, i], dtype=DTYPE)\n",
    "        sl = cv2.resize(sl, (IMG_SIZE, IMG_SIZE))\n",
    "        if sl.max() > 0:\n",
    "            sl /= sl.max()\n",
    "        slices.append(sl)\n",
    "\n",
    "    return np.stack(slices, axis=0)\n",
    "\n",
    "# ---------------- DATA GENERATOR ----------------\n",
    "class BraTSGenerator(Sequence):\n",
    "    def __init__(self, patient_dirs, shuffle=True):\n",
    "        self.patient_dirs = patient_dirs\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(patient_dirs))\n",
    "        self.on_epoch_end()\n",
    "        log(f\"Generator ready with {len(patient_dirs)} patients\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_dirs)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "        log(\"Epoch shuffle done\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient = self.patient_dirs[self.indices[idx]]\n",
    "        pid = os.path.basename(patient)\n",
    "\n",
    "        log(f\"Loading patient {pid}\")\n",
    "\n",
    "        flair = os.path.join(patient, f\"{pid}_flair.nii.gz\")\n",
    "        seg   = os.path.join(patient, f\"{pid}_seg.nii.gz\")\n",
    "\n",
    "        flair_slices = load_random_slices(flair)\n",
    "        seg_slices   = load_random_slices(seg)\n",
    "\n",
    "        flair_slices = np.expand_dims(flair_slices, -1)\n",
    "        flair_slices = np.repeat(flair_slices, 4, axis=-1)\n",
    "\n",
    "        X = flair_slices\n",
    "        y = np.expand_dims(seg_slices, -1)\n",
    "\n",
    "        log(f\"âœ“ Patient {pid} loaded successfully\")\n",
    "        return X, y\n",
    "\n",
    "# ---------------- PATIENT SPLIT ----------------\n",
    "patients = sorted([\n",
    "    os.path.join(database_path, p)\n",
    "    for p in os.listdir(database_path)\n",
    "    if p.startswith(\"BraTS2021_\")\n",
    "])\n",
    "\n",
    "split = int(0.8 * len(patients))\n",
    "train_gen = BraTSGenerator(patients[:split])\n",
    "val_gen   = BraTSGenerator(patients[split:], shuffle=False)\n",
    "\n",
    "log(f\"Train patients: {len(train_gen)} | Val patients: {len(val_gen)}\")\n",
    "\n",
    "# ---------------- METRICS ----------------\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    inter = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2. * inter) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + 1e-6)\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    inter = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - inter\n",
    "    return inter / (union + 1e-6)\n",
    "\n",
    "# ---------------- U-NET ----------------\n",
    "def unet(input_shape):\n",
    "    inp = layers.Input(input_shape)\n",
    "\n",
    "    c1 = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(inp)\n",
    "    c1 = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(c1)\n",
    "    p1 = layers.MaxPooling2D()(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(p1)\n",
    "    c2 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(c2)\n",
    "    p2 = layers.MaxPooling2D()(c2)\n",
    "\n",
    "    c3 = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(p2)\n",
    "    c3 = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(c3)\n",
    "\n",
    "    u1 = layers.UpSampling2D()(c3)\n",
    "    u1 = layers.Concatenate()([u1, c2])\n",
    "    c4 = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(u1)\n",
    "\n",
    "    u2 = layers.UpSampling2D()(c4)\n",
    "    u2 = layers.Concatenate()([u2, c1])\n",
    "    c5 = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(u2)\n",
    "\n",
    "    out = layers.Conv2D(1, 1, activation=\"sigmoid\", dtype=\"float32\")(c5)\n",
    "    return Model(inp, out)\n",
    "\n",
    "model = unet((IMG_SIZE, IMG_SIZE, 4))\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[dice_coef, iou]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ---------------- TRAIN ----------------\n",
    "log(\"Starting training...\")\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False\n",
    ")\n",
    "\n",
    "model.save(\"brats2021_unet_model.h5\")\n",
    "log(\"Training finished successfully â€” model saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
